{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8026978e",
   "metadata": {},
   "source": [
    "# Here is the code URL - https://github.com/aelassas/microservices\n",
    "\n",
    "# Env Setup \n",
    "https://builds.dotnet.microsoft.com/dotnet/Runtime/8.0.16/dotnet-runtime-8.0.16-win-x64.exe\n",
    "https://builds.dotnet.microsoft.com/dotnet/aspnetcore/Runtime/8.0.16/aspnetcore-runtime-8.0.16-win-x64.exe\n",
    "\n",
    "# installing the .NET dependencies\n",
    "dotnet add package Moq\n",
    "dotnet add package NUnit\n",
    "dotnet add package Microsoft.NET.Test.Sdk\n",
    "dotnet add package NUnit3TestAdapter\n",
    "dotnet add package coverlet.collector\n",
    "\n",
    "# Running the command\n",
    "dotnet test # Running the dotnet unit tests\n",
    "dotnet test --collect:\"XPlat Code Coverage\" # Code Coverage\n",
    "\n",
    "# Alternative Approach\n",
    "https://www.youtube.com/watch?v=-bmnmmnC_qU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d518fe1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: llama-index in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (0.12.35)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.5,>=0.4.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index) (0.4.7)\n",
      "Requirement already satisfied: llama-index-cli<0.5,>=0.4.1 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index) (0.4.1)\n",
      "Requirement already satisfied: llama-index-core<0.13,>=0.12.35 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index) (0.12.35)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.4,>=0.3.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index) (0.6.11)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.4,>=0.3.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index) (0.3.38)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5,>=0.4.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index) (0.4.3)\n",
      "Requirement already satisfied: llama-index-program-openai<0.4,>=0.3.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.4,>=0.3.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index) (0.3.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.5,>=0.4.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index) (0.4.7)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index) (3.9.1)\n",
      "Requirement already satisfied: openai>=1.14.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.78.1)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (3.11.18)\n",
      "Requirement already satisfied: aiosqlite in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.0.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (2.1.2)\n",
      "Requirement already satisfied: dataclasses-json in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (2025.3.2)\n",
      "Requirement already satisfied: httpx in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (3.4.2)\n",
      "Requirement already satisfied: numpy in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (2.2.5)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (11.2.1)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (2.11.4)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (2.32.3)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.35->llama-index) (2.0.40)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (4.13.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (1.17.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.35->llama-index) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.35->llama-index) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.35->llama-index) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.35->llama-index) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.35->llama-index) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.35->llama-index) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.35->llama-index) (1.20.0)\n",
      "Requirement already satisfied: griffe in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.35->llama-index) (1.7.3)\n",
      "Requirement already satisfied: jinja2 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.35->llama-index) (3.1.6)\n",
      "Requirement already satisfied: platformdirs in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.35->llama-index) (4.3.8)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (4.13.4)\n",
      "Requirement already satisfied: pandas in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.2.3)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (5.5.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (0.0.26)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.7)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (0.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.13,>=0.12.35->llama-index) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.13,>=0.12.35->llama-index) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.35->llama-index) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.35->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.35->llama-index) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.35->llama-index) (0.4.0)\n",
      "Requirement already satisfied: colorama in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from tqdm<5,>=4.66.1->llama-index-core<0.13,>=0.12.35->llama-index) (0.4.6)\n",
      "Requirement already satisfied: llama-cloud<0.2.0,>=0.1.13 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.19)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.22)\n",
      "Requirement already satisfied: llama-cloud-services>=0.6.22 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.22)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-cloud-services>=0.6.22->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (8.2.0)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-cloud-services>=0.6.22->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.1.0)\n",
      "Requirement already satisfied: joblib in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index) (1.5.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.35->llama-index) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.35->llama-index) (2.4.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.35->llama-index) (3.2.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.35->llama-index) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13,>=0.12.35->llama-index) (3.26.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13,>=0.12.35->llama-index) (25.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.35->llama-index) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from pandas->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from pandas->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from pandas->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5,>=0.4.0->llama-index) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: llama-index.llms-ollama in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (0.5.4)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.4 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index.llms-ollama) (0.12.35)\n",
      "Requirement already satisfied: ollama>=0.4.3 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index.llms-ollama) (0.4.8)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (3.11.18)\n",
      "Requirement already satisfied: aiosqlite in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.0.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (2.1.2)\n",
      "Requirement already satisfied: dataclasses-json in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (2025.3.2)\n",
      "Requirement already satisfied: httpx in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (2.2.5)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (11.2.1)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (2.11.4)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (2.32.3)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (2.0.40)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (4.13.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (1.17.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (1.20.0)\n",
      "Requirement already satisfied: griffe in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (1.7.3)\n",
      "Requirement already satisfied: jinja2 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (3.1.6)\n",
      "Requirement already satisfied: platformdirs in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (4.3.8)\n",
      "Requirement already satisfied: colorama in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from tqdm<5,>=4.66.1->llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (0.4.6)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (3.10)\n",
      "Requirement already satisfied: click in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (8.2.0)\n",
      "Requirement already satisfied: joblib in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (1.5.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (2024.11.6)\n",
      "Requirement already satisfied: anyio in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (2.4.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (3.2.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (3.26.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (25.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.4->llama-index.llms-ollama) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: nest_asyncio in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (1.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: tree_sitter in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (0.24.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: tree_sitter_language_pack in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (0.7.3)\n",
      "Requirement already satisfied: tree-sitter>=0.23.2 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from tree_sitter_language_pack) (0.24.0)\n",
      "Requirement already satisfied: tree-sitter-c-sharp>=0.23.1 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from tree_sitter_language_pack) (0.23.1)\n",
      "Requirement already satisfied: tree-sitter-embedded-template>=0.23.2 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from tree_sitter_language_pack) (0.23.2)\n",
      "Requirement already satisfied: tree-sitter-yaml>=0.7.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from tree_sitter_language_pack) (0.7.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: llama-index-embeddings-huggingface in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (0.5.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.31.2)\n",
      "Requirement already satisfied: llama-index-core<0.13,>=0.12.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-embeddings-huggingface) (0.12.35)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.1 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-embeddings-huggingface) (4.1.0)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.11.18)\n",
      "Requirement already satisfied: aiosqlite in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.0.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2.1.2)\n",
      "Requirement already satisfied: dataclasses-json in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2025.3.2)\n",
      "Requirement already satisfied: httpx in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2.2.5)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (11.2.1)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2.11.4)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2.32.3)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2.0.40)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (4.13.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.17.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.20.0)\n",
      "Requirement already satisfied: griffe in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.7.3)\n",
      "Requirement already satisfied: jinja2 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.1.6)\n",
      "Requirement already satisfied: platformdirs in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (4.3.8)\n",
      "Requirement already satisfied: colorama in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from tqdm<5,>=4.66.1->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.4.6)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.10)\n",
      "Requirement already satisfied: filelock in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.18.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (25.0)\n",
      "Requirement already satisfied: click in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (8.2.0)\n",
      "Requirement already satisfied: joblib in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.5.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2025.4.26)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (4.51.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.7.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.15.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.5.3)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.2.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.14.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.26.1)\n",
      "Requirement already satisfied: anyio in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from anyio->httpx->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\github\\unit-test-generator\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "## Run all the setup required to run this code\n",
    "%pip install llama-index\n",
    "%pip install llama-index.llms-ollama\n",
    "%pip install nest_asyncio\n",
    "%pip install tree_sitter\n",
    "%pip install tree_sitter_language_pack\n",
    "%pip install llama-index-embeddings-huggingface "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b64e1752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testcase=\"CartMicroservice.UnitTests\" coverage.line-rate=\"0.0629\" coverage.branch-rate=\"0\"\n",
      "testcase=\"CatalogMicroservice.UnitTests\" coverage.line-rate=\"0.0823\" coverage.branch-rate=\"0.07139999999999999\"\n",
      "testcase=\"IdentityMicroservice.UnitTests\" coverage.line-rate=\"0.3343\" coverage.branch-rate=\"0.475\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Test Directory Path\n",
    "TEST_DIRECTORY = \"C:\\\\GitHub\\\\microservices-sample\\\\microservices\\\\tests\"\n",
    "\n",
    "target_source_list = [\n",
    "    \"C:\\\\GitHub\\\\microservices-sample\\\\microservices\\\\src\\microservices\\\\CartMicroservice\\\\Controllers\\\\CartController.cs\"\n",
    "]\n",
    "\n",
    "\n",
    "testcases = os.listdir(TEST_DIRECTORY)\n",
    "\n",
    "#create a folder for this specific test run, where all the results will be achived\n",
    "#testrun_folder = f\"TestRun-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "#os.makedirs(testrun_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "def cleanup_testrun( testdir, testlist, result_folder=\"TestResults\" ):\n",
    "\n",
    "    ## before the start of the test, remove all 'TestResults' folder \n",
    "    for testcase in testlist:\n",
    "        test_result_path = os.path.join(testdir, testcase, 'TestResults')\n",
    "        if os.path.exists(test_result_path):\n",
    "            shutil.rmtree(test_result_path)\n",
    "\n",
    "cleanup_testrun( TEST_DIRECTORY, testcases, result_folder=\"TestResults\" )\n",
    "\n",
    "for testcase in testcases:\n",
    "    \n",
    "    testcase_dir = os.path.join(TEST_DIRECTORY, testcase)\n",
    "    os.system(f'dotnet test --collect:\"XPlat Code Coverage\" \"{testcase_dir}\"')\n",
    "\n",
    "    coverage_found = False\n",
    "    for root, dirs, files in os.walk(testcase_dir):\n",
    "        if 'coverage.cobertura.xml' in files:\n",
    "            \n",
    "            coverage_file_path = os.path.join(root, 'coverage.cobertura.xml')\n",
    "            \n",
    "            with open(coverage_file_path, 'r', encoding='utf-8') as f:\n",
    "                coverage_xml_content = f.read()\n",
    "            \n",
    "            tree = ET.ElementTree(ET.fromstring(coverage_xml_content))\n",
    "            \n",
    "            root_elem = tree.getroot()\n",
    "            line_rate = root_elem.attrib.get('line-rate')\n",
    "            branch_rate = root_elem.attrib.get('branch-rate')\n",
    "            \n",
    "            print(f'testcase=\"{testcase}\" coverage.line-rate=\"{line_rate}\" coverage.branch-rate=\"{branch_rate}\"')\n",
    "            coverage_found = True\n",
    "            break\n",
    "    \n",
    "    if not coverage_found:\n",
    "        print('coverage.cobertura.xml file not found')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c8b654f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup_testrun( TEST_DIRECTORY, testcases, result_folder=\"TestResults\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ef8bb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\unit-test-generator\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "## Import all llama-index libs here\n",
    "\n",
    "from llama_index.core import  Settings, Document, VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "from llama_index.core import ChatPromptTemplate\n",
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "\n",
    "import os\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf97523a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the value for Setting \n",
    "llm = Ollama( model=\"codestral\", request_timeout=300)\n",
    "#embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "Settings.llm = llm\n",
    "\n",
    "#Settings.embed_model = HuggingFaceEmbedding(\n",
    "#    model_name=\"BAAI/bge-small-en-v1.5\"\n",
    "#)\n",
    "\n",
    "#docs = SimpleDirectoryReader(\n",
    "#    \"C:\\\\GitHub\\\\microservices-sample\\\\microservices\\\\src\\microservices\\\\CartMicroservice\",\n",
    "#    required_exts=[\".cs\"]\n",
    "#).load_data()\n",
    "\n",
    "target_source_list = [\n",
    "    \"C:\\\\GitHub\\\\microservices-sample\\\\microservices\\\\src\\microservices\\\\CartMicroservice\\\\Controllers\\\\CartController.cs\"\n",
    "]\n",
    "\n",
    "docs = []\n",
    "\n",
    "for file_path in target_source_list:\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "        docs.append(Document(text=content, metadata={\"file_path\": file_path}))\n",
    "\n",
    "    index = VectorStoreIndex.from_documents(docs)\n",
    "\n",
    "    message_templates = [\n",
    "        ChatMessage(role=MessageRole.SYSTEM, content=\"You are an unit test expert who can analyse a file and create execution ready unit-test cases\"),\n",
    "        ChatMessage(role=MessageRole.USER, content=f\"Analyse this source code {content} and create XUnit unit test cases based on the source code provided\" )\n",
    "    ]\n",
    "\n",
    "    chat_prompt_template = ChatPromptTemplate(message_templates=message_templates)\n",
    "    #chat_message = chat_template.format_messages(source_code=content)\n",
    "    #chat_engine = index.as_chat_engine(verbose=False, ChatPromptTemplate=chat_template)\n",
    "\n",
    "    response = Settings.llm.chat(  chat_prompt_template.format_messages() )\n",
    " \n",
    "    #resposne = chat_engine.chat(message=f\"generate XUnit test cases for the source code - {content}\")  \n",
    "    #response = chat_engine.chat( message=\"generate XUnit unit test cases\")\n",
    "    print(f'Response -> {response}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8549981d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the value for Setting \n",
    "Settings.llm  = Ollama( model=\"granite-code:20b\", request_timeout=300)\n",
    "\n",
    "relevant_sub_folders = [\n",
    "    \"Model\",\n",
    "    \"Repository\"\n",
    "]\n",
    "\n",
    "target_source_list = [\n",
    "    \"C:\\\\GitHub\\\\microservices-sample\\\\microservices\\\\src\\\\microservices\\\\CartMicroservice\"\n",
    "]\n",
    "\n",
    "dependency_content = \"\"\n",
    "\n",
    "for target_source in target_source_list:\n",
    "    \n",
    "    dependency_content = \"\"\n",
    "\n",
    "    #within the target source, read all the important directories\n",
    "    for sub_folder in relevant_sub_folders:\n",
    "        sub_folder_path = os.path.join(target_source, sub_folder)\n",
    "        if os.path.exists(sub_folder_path) and os.path.isdir(sub_folder_path):\n",
    "            for fname in os.listdir(sub_folder_path):\n",
    "                if fname.endswith('.cs'):\n",
    "                    file_path = os.path.join(sub_folder_path, fname)\n",
    "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        file_content = f.read()\n",
    "                        dependency_content += file_content + \"\\n---\\n\"\n",
    "\n",
    "filepath = \"C:\\\\GitHub\\\\microservices-sample\\\\microservices\\\\src\\\\microservices\\\\CartMicroservice\\\\Controllers\\\\CartController.cs\"\n",
    "\n",
    "with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "    controller_content = f.read()\n",
    "\n",
    "message_templates = [\n",
    "    ChatMessage(role=MessageRole.SYSTEM, content=\"You are an unit test expert who can analyse a file and create execution ready unit-test cases\"),\n",
    "    ChatMessage(role=MessageRole.ASSISTANT, content=f\"Provide the source code\" ),\n",
    "    ChatMessage(role=MessageRole.USER, content=f\"Here is the source code for which the XUnit test needs to be created {controller_content}\" ),\n",
    "    ChatMessage(role=MessageRole.ASSISTANT, content=f\"Provide all dependencies in a single file, each dependency must be separated by '---' characters\" ),\n",
    "    ChatMessage(role=MessageRole.USER, content=f\"Here are all the dependencies - {dependency_content}\" ),\n",
    "    ChatMessage(role=MessageRole.ASSISTANT, content=f\"Any specific instructions before generation ?\" ),\n",
    "    ChatMessage(role=MessageRole.USER, content=f\"Generate XUnit specific unit test cases for the source code provided, do not add additional classes\" ),\n",
    "\n",
    "]\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate( message_templates=message_templates)\n",
    "response = Settings.llm.chat(  chat_prompt_template.format_messages() )\n",
    "print(f'Response -> {response}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f03b72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the value for Setting \n",
    "Settings.llm  = Ollama( model=\"llama4:scout\", request_timeout=1000)\n",
    "\n",
    "relevant_sub_folders = [\n",
    "    \"Model\",\n",
    "    \"Repository\"\n",
    "]\n",
    "\n",
    "target_source_list = [\n",
    "    \"C:\\\\GitHub\\\\microservices-sample\\\\microservices\\\\src\\\\microservices\\\\CartMicroservice\"\n",
    "]\n",
    "\n",
    "dependency_content = \"\"\n",
    "\n",
    "for target_source in target_source_list:\n",
    "    \n",
    "    dependency_content = \"\"\n",
    "\n",
    "    #within the target source, read all the important directories\n",
    "    for sub_folder in relevant_sub_folders:\n",
    "        sub_folder_path = os.path.join(target_source, sub_folder)\n",
    "        if os.path.exists(sub_folder_path) and os.path.isdir(sub_folder_path):\n",
    "            for fname in os.listdir(sub_folder_path):\n",
    "                if fname.endswith('.cs'):\n",
    "                    file_path = os.path.join(sub_folder_path, fname)\n",
    "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        file_content = f.read()\n",
    "                        dependency_content += file_content + \"\\n---\\n\"\n",
    "\n",
    "filepath = \"C:\\\\GitHub\\\\microservices-sample\\\\microservices\\\\src\\\\microservices\\\\CartMicroservice\\\\Controllers\\\\CartController.cs\"\n",
    "\n",
    "with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "    controller_content = f.read()\n",
    "\n",
    "message_templates = [\n",
    "    ChatMessage(role=MessageRole.SYSTEM, content=\"You are a developer who generates XUnit unit test cases\"),\n",
    "    ChatMessage(role=MessageRole.USER, content=\"Generate a blank template for XUnit unit-test case for csharp\"),\n",
    "    ChatMessage(role=MessageRole.USER, content=f\"Generate positive unit test cases for the functions in the source code - {controller_content}\"),\n",
    "    ChatMessage(role=MessageRole.ASSISTANT, content=f\"Share all dependencies for this class separated by --- characters\"),\n",
    "    ChatMessage(role=MessageRole.USER, content=f\"Here are all the dependencies - {dependency_content} - make sure all references are included and the code compiles\"),\n",
    "    ChatMessage(role=MessageRole.USER, content=f\"Make sure all variables are initialized with sample data\")\n",
    "]\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate( message_templates=message_templates)\n",
    "response = Settings.llm.chat(  chat_prompt_template.format_messages() )\n",
    "print(f'Response -> {response}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
